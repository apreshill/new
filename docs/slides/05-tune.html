<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Build a fine-tuned model</title>
    <meta charset="utf-8" />
    <meta name="author" content="Alison Hill" />
    <meta name="date" content="2021-09-14" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/countdown/countdown.css" rel="stylesheet" />
    <script src="libs/countdown/countdown.js"></script>
    <!---import JQuery-->

    <script
      src="https://code.jquery.com/jquery-3.4.1.min.js"
      integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
      crossorigin="anonymous">
    </script>

    <!--add parent selector-->

    <script>

    $( document ).ready( function(){

      $( "pre")
          .parents( ".remark-slide-content" )
          .addClass( "code-slide-background" );
      
    });
      
    </script>
    <link rel="stylesheet" href="assets/css/my-theme.css" type="text/css" />
    <link rel="stylesheet" href="assets/css/my-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">







class: title-slide, center, bottom

# Build a fine-tuned model

## Tidymodels, virtually &amp;mdash; Session 05

### Alison Hill 



---


.pull-left[

### Single decision tree

```r
tree_mod &lt;- 
  decision_tree(engine = "rpart") %&gt;% 
  set_mode("classification")

tree_wf &lt;-
  workflow() %&gt;% 
  add_formula(Class ~ .) %&gt;% 
  add_model(tree_mod)

set.seed(100)
tree_res &lt;- 
  tree_wf %&gt;% 
  fit_resamples(resamples = alz_folds,
                control = control_resamples(save_pred = TRUE))

tree_res %&gt;% 
  collect_metrics()
# # A tibble: 2 × 6
#   .metric  .estimator  mean     n std_err .config           
#   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;             
# 1 accuracy binary     0.756    10  0.0245 Preprocessor1_Mod…
# 2 roc_auc  binary     0.770    10  0.0255 Preprocessor1_Mod…
```
]

--

.pull-right[


### A random forest of trees

```r
rf_mod &lt;-
  rand_forest(engine = "ranger") %&gt;% 
  set_mode("classification")

rf_wf &lt;-
  tree_wf %&gt;% 
  update_model(rf_mod)

set.seed(100)
rf_res &lt;- rf_wf %&gt;% 
  fit_resamples(resamples = alz_folds,
                control = control_resamples(save_pred = TRUE)) 

rf_res %&gt;% 
  collect_metrics()
# # A tibble: 2 × 6
#   .metric  .estimator  mean     n std_err .config           
#   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;             
# 1 accuracy binary     0.837    10  0.0172 Preprocessor1_Mod…
# 2 roc_auc  binary     0.886    10  0.0171 Preprocessor1_Mod…
```
]

---


.pull-left[

### Single decision tree
&lt;img src="figs/05/unnamed-chunk-3-1.png" width="504" style="display: block; margin: auto;" /&gt;
]

--

.pull-right[


### A random forest of trees
&lt;img src="figs/05/unnamed-chunk-4-1.png" width="504" style="display: block; margin: auto;" /&gt;
]

---
class: your-turn

# Your turn 1

Challenge: Fit 3 more random forest models, each using 3, 8, and 30 variables at each split. Update your `rf_wf` with each new model. Which value maximizes the area under the ROC curve?

<div class="countdown" id="timer_61413e6b" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">03</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>


---

```r
rf3_mod &lt;- rf_mod %&gt;% 
* set_args(mtry = 3)

rf8_mod &lt;- rf_mod %&gt;% 
* set_args(mtry = 8)

rf30_mod &lt;- rf_mod %&gt;% 
* set_args(mtry = 30)
```

---

```r
rf3_wf &lt;- rf_wf %&gt;% 
  update_model(rf3_mod)

set.seed(100)
rf3_wf %&gt;% 
  fit_resamples(resamples = alz_folds) %&gt;% 
  collect_metrics()
# # A tibble: 2 × 6
#   .metric  .estimator  mean     n std_err .config           
#   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;             
# 1 accuracy binary     0.786    10  0.0145 Preprocessor1_Mod…
# 2 roc_auc  binary     0.862    10  0.0167 Preprocessor1_Mod…
```

---

```r
rf8_wf &lt;- rf_wf %&gt;% 
  update_model(rf8_mod)

set.seed(100)
rf8_wf %&gt;% 
  fit_resamples(resamples = alz_folds) %&gt;% 
  collect_metrics()
# # A tibble: 2 × 6
#   .metric  .estimator  mean     n std_err .config           
#   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;             
# 1 accuracy binary     0.817    10  0.0137 Preprocessor1_Mod…
# 2 roc_auc  binary     0.886    10  0.0152 Preprocessor1_Mod…
```

---

```r
rf30_wf &lt;- rf_wf %&gt;% 
  update_model(rf30_mod)

set.seed(100)
rf30_wf %&gt;% 
  fit_resamples(resamples = alz_folds) %&gt;% 
  collect_metrics()
# # A tibble: 2 × 6
#   .metric  .estimator  mean     n std_err .config           
#   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;             
# 1 accuracy binary     0.846    10  0.0140 Preprocessor1_Mod…
# 2 roc_auc  binary     0.897    10  0.0133 Preprocessor1_Mod…
```


---
class: middle, center, frame


# tune 

Functions for fitting and tuning models

&lt;https://tune.tidymodels.org&gt;

&lt;iframe src="https://tune.tidymodels.org" width="100%" height="400px"&gt;&lt;/iframe&gt;

---
class: middle, center

# `tune()`

A placeholder for hyper-parameters to be "tuned"


```r
nearest_neighbor(neighbors = tune())
```


---

.center[
# `tune_grid()`

A version of `fit_resamples()` that performs a grid search for the best combination of tuned hyper-parameters.
]

.pull-left[


```r
tune_grid(
  object, 
  resamples, 
  ..., 
  grid = 10, 
  metrics = NULL, 
  control = control_grid()
)
```

]

---

.center[
# `tune_grid()`

A version of `fit_resamples()` that performs a grid search for the best combination of tuned hyper-parameters.
]

.pull-left[


```r
tune_grid(
* object,
  resamples, 
  ..., 
  grid = 10, 
  metrics = NULL, 
  control = control_grid()
)
```

]

--

.pull-right[
One of:

+ A parsnip `model` object

+ A `workflow`

]

---

.center[
# `tune_grid()`

A version of `fit_resamples()` that performs a grid search for the best combination of tuned hyper-parameters.
]

.pull-left[


```r
tune_grid(
* object,
* preprocessor,
  resamples, 
  ..., 
  grid = 10, 
  metrics = NULL, 
  control = control_grid()
)
```

]

.pull-right[
A `model` + `recipe`
]

---

.center[
# `tune_grid()`

A version of `fit_resamples()` that performs a grid search for the best combination of tuned hyper-parameters.
]

.pull-left[


```r
tune_grid(
  object, 
  resamples, 
  ..., 
* grid = 10,
  metrics = NULL, 
  control = control_grid()
)
```

]

.pull-right[
One of:

+ A positive integer. 

+ A data frame of tuning combinations.

]

---

.center[

# `tune_grid()`

A version of `fit_resamples()` that performs a grid search for the best combination of tuned hyper-parameters.

]

.pull-left[


```r
tune_grid(
  object, 
  resamples, 
  ..., 
* grid = 10,
  metrics = NULL, 
  control = control_grid()
)
```

]

.pull-right[
Number of candidate parameter sets to be created automatically; `10` is the default.
]

---

```r
data("ad_data")
alz &lt;- ad_data

# data splitting
set.seed(100) # Important!
alz_split  &lt;- initial_split(alz, strata = Class, prop = .9)
alz_train  &lt;- training(alz_split)
alz_test   &lt;- testing(alz_split)

# data resampling
set.seed(100)
alz_folds &lt;- 
    vfold_cv(alz_train, v = 10, strata = Class)
```


---
class: your-turn

# Your Turn 2

Here's our random forest model plus workflow to work with.


```r
rf_mod &lt;- 
  rand_forest(engine = "ranger") %&gt;% 
  set_mode("classification")

rf_wf &lt;-
  workflow() %&gt;% 
  add_formula(Class ~ .) %&gt;% 
  add_model(rf_mod)
```

---
class: your-turn

# Your Turn 2

Here is the output from `fit_resamples()`...


```r
set.seed(100) # Important!
rf_results &lt;-
  rf_wf %&gt;% 
  fit_resamples(resamples = alz_folds)

rf_results %&gt;% 
  collect_metrics()
# # A tibble: 2 × 6
#   .metric  .estimator  mean     n std_err .config           
#   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;             
# 1 accuracy binary     0.826    10  0.0181 Preprocessor1_Mod…
# 2 roc_auc  binary     0.882    10  0.0248 Preprocessor1_Mod…
```


---
class: your-turn

# Your Turn 2

Edit the random forest model to tune the `mtry` and `min_n` hyperparameters. 

Update your workflow to use the tuned model.

Then use `tune_grid()` to find the best combination of hyper-parameters to maximize `roc_auc`; let tune set up the grid for you.

How does it compare to the average ROC AUC across folds from `fit_resamples()`?

<div class="countdown" id="timer_61413d71" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">05</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---


```r
rf_tuner &lt;- 
  rand_forest(engine = "ranger", 
              mtry = tune(),
              min_n = tune()) %&gt;% 
  set_mode("classification")

rf_wf &lt;-
  rf_wf %&gt;% 
  update_model(rf_tuner)

set.seed(100) # Important!
rf_results &lt;-
  rf_wf %&gt;% 
  tune_grid(resamples = alz_folds)
```

---


```r
rf_results %&gt;% 
  collect_metrics() 
# # A tibble: 20 × 8
#     mtry min_n .metric  .estimator  mean     n std_err
#    &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;
#  1    40     3 accuracy binary     0.853    10  0.0158
#  2    40     3 roc_auc  binary     0.889    10  0.0241
#  3    60    20 accuracy binary     0.857    10  0.0190
#  4    60    20 roc_auc  binary     0.891    10  0.0225
#  5   104    24 accuracy binary     0.864    10  0.0156
#  6   104    24 roc_auc  binary     0.881    10  0.0233
#  7    19    15 accuracy binary     0.837    10  0.0160
#  8    19    15 roc_auc  binary     0.889    10  0.0245
#  9   124    26 accuracy binary     0.860    10  0.0172
# 10   124    26 roc_auc  binary     0.885    10  0.0222
# # … with 10 more rows, and 1 more variable: .config &lt;chr&gt;
```

---

```r
rf_results %&gt;% 
  collect_metrics(summarize = FALSE) 
# # A tibble: 200 × 7
#    id      mtry min_n .metric  .estimator .estimate .config 
#    &lt;chr&gt;  &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;   
#  1 Fold01    40     3 accuracy binary         0.839 Preproc…
#  2 Fold01    40     3 roc_auc  binary         0.869 Preproc…
#  3 Fold02    40     3 accuracy binary         0.806 Preproc…
#  4 Fold02    40     3 roc_auc  binary         0.869 Preproc…
#  5 Fold03    40     3 accuracy binary         0.933 Preproc…
#  6 Fold03    40     3 roc_auc  binary         0.966 Preproc…
#  7 Fold04    40     3 accuracy binary         0.8   Preproc…
#  8 Fold04    40     3 roc_auc  binary         0.847 Preproc…
#  9 Fold05    40     3 accuracy binary         0.867 Preproc…
# 10 Fold05    40     3 roc_auc  binary         0.977 Preproc…
# # … with 190 more rows
```


---

.center[
# `tune_grid()`

A version of `fit_resamples()` that performs a grid search for the best combination of tuned hyper-parameters.

]

.pull-left[


```r
tune_grid(
  object, 
  resamples, 
  ..., 
* grid = df,
  metrics = NULL, 
  control = control_grid()
)
```

]

.pull-right[
A data frame of tuning combinations.
]

---
class: middle, center

# `expand_grid()`

Takes one or more vectors, and returns a data frame holding all combinations of their values.


```r
expand_grid(mtry = c(1, 5), min_n = 1:3)
# # A tibble: 6 × 2
#    mtry min_n
#   &lt;dbl&gt; &lt;int&gt;
# 1     1     1
# 2     1     2
# 3     1     3
# 4     5     1
# 5     5     2
# 6     5     3
```

--

.footnote[tidyr package; see also base `expand.grid()`]


---
class: middle
name: show-best

.center[
# `show_best()`

Shows the .display[n] most optimum combinations of hyper-parameters
]


```r
rf_results %&gt;% 
  show_best(metric = "roc_auc", n = 5)
```

---
template: show-best


```
# # A tibble: 5 × 8
#    mtry min_n .metric .estimator  mean     n std_err .config
#   &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  
# 1    91     9 roc_auc binary     0.893    10  0.0243 Prepro…
# 2    71    33 roc_auc binary     0.892    10  0.0230 Prepro…
# 3    60    20 roc_auc binary     0.891    10  0.0225 Prepro…
# 4    28    29 roc_auc binary     0.889    10  0.0249 Prepro…
# 5    19    15 roc_auc binary     0.889    10  0.0245 Prepro…
```


---
class: middle, center

# `autoplot()`

Quickly visualize tuning results



```r
rf_results %&gt;% autoplot()
```

&lt;img src="figs/05/rf-plot-1.png" width="504" style="display: block; margin: auto;" /&gt;

---
class: middle, center

&lt;img src="figs/05/unnamed-chunk-26-1.png" width="504" style="display: block; margin: auto;" /&gt;



---
class: middle
name: select-best

.center[
# `select_best()`

Shows the .display[top] combination of hyper-parameters.
]


```r
alz_best &lt;-
  rf_results %&gt;% 
  select_best(metric = "roc_auc")

alz_best
```

---
template: select-best


```
# # A tibble: 1 × 3
#    mtry min_n .config              
#   &lt;int&gt; &lt;int&gt; &lt;chr&gt;                
# 1    91     9 Preprocessor1_Model09
```

---
class: middle

.center[
# `finalize_workflow()`

Replaces `tune()` placeholders in a model/recipe/workflow with a set of hyper-parameter values.
]


```r
last_rf_workflow &lt;- 
  rf_wf %&gt;%
  finalize_workflow(alz_best) 
```

---
background-image: url(images/diamonds.jpg)
background-size: contain
background-position: left
class: middle, center
background-color: #f5f5f5

.pull-right[
## We are ready to touch the jewels...

## The .display[testing set]!

]


---
class: middle

.center[

# `last_fit()`

]


```r
last_rf_fit &lt;-
  last_rf_workflow %&gt;% 
  last_fit(split = alz_split)
```

---


```r
last_rf_fit
# # Resampling results
# # Manual resampling 
# # A tibble: 1 × 6
#   splits           id    .metrics .notes .predictions .workflow
#   &lt;list&gt;           &lt;chr&gt; &lt;list&gt;   &lt;list&gt; &lt;list&gt;       &lt;list&gt;   
# 1 &lt;split [300/33]&gt; trai… &lt;tibble… &lt;tibb… &lt;tibble [33… &lt;workflo…
```

---
class: your-turn

# Your Turn 3

Use `select_best()`, `finalize_workflow()`, and `last_fit()` to take the best combination of hyper-parameters from `rf_results` and use them to predict the test set.

How does our actual test ROC AUC compare to our cross-validated estimate?

<div class="countdown" id="timer_61413ec1" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">05</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---


```r
alz_best &lt;-
  rf_results %&gt;% 
  select_best(metric = "roc_auc")

last_rf_workflow &lt;- 
  rf_wf%&gt;%
  finalize_workflow(alz_best) 

last_rf_fit &lt;-
  last_rf_workflow %&gt;% 
  last_fit(split = alz_split)

last_rf_fit %&gt;% 
  collect_metrics()
```

---
class: middle, frame

.center[
# Final metrics
]


```r
last_rf_fit %&gt;% 
  collect_metrics()
# # A tibble: 2 × 4
#   .metric  .estimator .estimate .config             
#   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
# 1 accuracy binary         0.818 Preprocessor1_Model1
# 2 roc_auc  binary         0.819 Preprocessor1_Model1
```


---
class: middle

.center[
# Final test predictions
]


```r
last_rf_fit %&gt;% 
  collect_predictions()
# # A tibble: 33 × 7
#    id               .pred_Impaired .pred_Control  .row .pred_class
#    &lt;chr&gt;                     &lt;dbl&gt;         &lt;dbl&gt; &lt;int&gt; &lt;fct&gt;      
#  1 train/test split        0.264           0.736    13 Control    
#  2 train/test split        0.223           0.777    14 Control    
#  3 train/test split        0.256           0.744    33 Control    
#  4 train/test split        0.434           0.566    43 Control    
#  5 train/test split        0.0765          0.924    46 Control    
#  6 train/test split        0.270           0.730    48 Control    
#  7 train/test split        0.00933         0.991    49 Control    
#  8 train/test split        0.808           0.192    56 Impaired   
#  9 train/test split        0.629           0.371    67 Impaired   
# 10 train/test split        0.110           0.890    68 Control    
# # … with 23 more rows, and 2 more variables: Class &lt;fct&gt;,
# #   .config &lt;chr&gt;
```

---


```r
roc_values &lt;- 
  last_rf_fit %&gt;% 
  collect_predictions() %&gt;% 
  roc_curve(truth = Class, estimate = .pred_Impaired)
autoplot(roc_values)
```

&lt;img src="figs/05/unnamed-chunk-35-1.png" width="50%" style="display: block; margin: auto;" /&gt;

---

# The set-up


```r
set.seed(100) # Important!

# holdout method
alz_split  &lt;- initial_split(alz, strata = Class, prop = .9)
alz_train  &lt;- training(alz_split)
alz_test   &lt;- testing(alz_split)

# add cross-validation
set.seed(100)
alz_folds &lt;- 
    vfold_cv(alz_train, v = 10, strata = Class)
```

---

# The tune-up


```r
# here comes the actual ML bits…

# pick model to tune
rf_tuner &lt;- 
  rand_forest(engine = "ranger", 
              mtry = tune(),
              min_n = tune()) %&gt;% 
  set_mode("classification")

rf_wf &lt;-
  workflow() %&gt;% 
  add_formula(Class ~ .) %&gt;% 
  add_model(rf_tuner)

rf_results &lt;-
  rf_wf %&gt;% 
  tune_grid(resamples = alz_folds,
            control = control_grid(save_pred = TRUE))
```

---

# Quick check-in...


```r
rf_results %&gt;%
  collect_predictions() %&gt;% 
  group_by(.config, mtry, min_n) %&gt;% 
  summarize(folds = n_distinct(id))
# # A tibble: 10 × 4
# # Groups:   .config, mtry [10]
#    .config                mtry min_n folds
#    &lt;chr&gt;                 &lt;int&gt; &lt;int&gt; &lt;int&gt;
#  1 Preprocessor1_Model01    72    31    10
#  2 Preprocessor1_Model02    44    21    10
#  3 Preprocessor1_Model03    59    28    10
#  4 Preprocessor1_Model04    31    11    10
#  5 Preprocessor1_Model05    88    38    10
#  6 Preprocessor1_Model06    94    33    10
#  7 Preprocessor1_Model07   118    15    10
#  8 Preprocessor1_Model08     6    17    10
#  9 Preprocessor1_Model09    26     9    10
# 10 Preprocessor1_Model10   106     2    10
```


---

# The match up!

.pull-left[

```r
show_best(rf_results, metric = "roc_auc", n = 5)
# # A tibble: 5 × 8
#    mtry min_n .metric .estimator  mean     n std_err .config
#   &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  
# 1    44    21 roc_auc binary     0.894    10  0.0227 Prepro…
# 2    31    11 roc_auc binary     0.891    10  0.0224 Prepro…
# 3    59    28 roc_auc binary     0.888    10  0.0229 Prepro…
# 4    26     9 roc_auc binary     0.888    10  0.0259 Prepro…
# 5   106     2 roc_auc binary     0.887    10  0.0248 Prepro…

# pick final model workflow
alz_best &lt;-
  rf_results %&gt;% 
  select_best(metric = "roc_auc")

alz_best
# # A tibble: 1 × 3
#    mtry min_n .config              
#   &lt;int&gt; &lt;int&gt; &lt;chr&gt;                
# 1    44    21 Preprocessor1_Model02
```
]

.pull-right[
&lt;img src="figs/05/unnamed-chunk-40-1.png" width="504" style="display: block; margin: auto;" /&gt;

]


---

# The wrap-up

.pull-left[

```r
last_rf_workflow &lt;- 
  rf_wf %&gt;%
  finalize_workflow(alz_best) 

last_rf_workflow
# ══ Workflow ════════════════════════════════════════════════════════════════════
# Preprocessor: Formula
# Model: rand_forest()
# 
# ── Preprocessor ────────────────────────────────────────────────────────────────
# Class ~ .
# 
# ── Model ───────────────────────────────────────────────────────────────────────
# Random Forest Model Specification (classification)
# 
# Main Arguments:
#   mtry = 44
#   min_n = 21
# 
# Computational engine: ranger
```
]

--

.pull-right[

```r
# train + test final model
last_rf_fit &lt;-
  last_rf_workflow %&gt;% 
  last_fit(split = alz_split)

# explore final model
last_rf_fit %&gt;% 
  collect_metrics()
# # A tibble: 2 × 4
#   .metric  .estimator .estimate .config             
#   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
# 1 accuracy binary         0.788 Preprocessor1_Model1
# 2 roc_auc  binary         0.815 Preprocessor1_Model1

last_rf_fit %&gt;% 
  collect_predictions() %&gt;% 
  roc_curve(truth = Class, estimate = .pred_Impaired) %&gt;% 
  autoplot()
```
]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightLanguage": "r",
"highlightStyle": "xcode",
"slideNumberFormat": "",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
